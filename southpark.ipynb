{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "southpark.ipynb",
      "provenance": [],
      "mount_file_id": "1eLAht3SsV9ee5yXbNT5wDwi0zOPu1tq4",
      "authorship_tag": "ABX9TyN0qqUzlYSrmahDGHcUZOWH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdMkD6K_yXy_",
        "colab_type": "text"
      },
      "source": [
        "# Загрузка пакетов и данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xipnivra4Ylq",
        "colab_type": "text"
      },
      "source": [
        "Для начала надо загрузить необходимые пакеты и данные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCQJOyiHdfhW",
        "colab_type": "code",
        "outputId": "4eb3d023-f453-4ffa-f7c7-e0220a17b1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install profanity_check  # Проверка оскорбительности"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting profanity_check\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/dd/bdbfe61f11b328a583960ece9145a3e080082475f52f9f56795b22ab4c41/profanity_check-1.0.3-py3-none-any.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from profanity_check) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->profanity_check) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->profanity_check) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->profanity_check) (1.4.1)\n",
            "Installing collected packages: profanity-check\n",
            "Successfully installed profanity-check-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-8t50Rqz2rr",
        "colab_type": "code",
        "outputId": "3abd591f-ec62-4463-9328-4e099bf5f512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "!pip install spacy  # Для анализа текста"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz50aKS_dbtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Понадобится для всего\n",
        "import pandas as pd\n",
        "\n",
        "# Понадобится для изучения грубости высказываний\n",
        "from collections import Counter\n",
        "from profanity_check import predict\n",
        "\n",
        "# Понадобится для предсказания персонажа по тексту фразы\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import TransformerMixin \n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-YRUzXwdpiy",
        "colab_type": "code",
        "outputId": "9c14462e-6354-413f-9c59-7a9100b7067a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/hw2/All-seasons.csv')\n",
        "\n",
        "# Как выглядит датафрейм\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Episode</th>\n",
              "      <th>Character</th>\n",
              "      <th>Line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Stan</td>\n",
              "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Kyle</td>\n",
              "      <td>Going away? For how long?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Stan</td>\n",
              "      <td>Forever.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Chef</td>\n",
              "      <td>I'm sorry boys.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Stan</td>\n",
              "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Season Episode Character                                               Line\n",
              "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
              "1     10       1      Kyle                        Going away? For how long?\\n\n",
              "2     10       1      Stan                                         Forever.\\n\n",
              "3     10       1      Chef                                  I'm sorry boys.\\n\n",
              "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpL5VsYfH7a-",
        "colab_type": "text"
      },
      "source": [
        "Итак, мы имеем датасет, в котором каждую строчку занимает одна фраза персонажа, указан персонаж, а также серия и сезон. Последние два параметра я использовать не буду. Также я буду изучать только топ-10 по количеству высказываний персонажей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtA3HAh4n2G",
        "colab_type": "text"
      },
      "source": [
        "Создам список главных персонажей (топ-10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVrRD4Z5k_dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_characters = []\n",
        "for i in range(10):\n",
        "    main_characters.append(Counter(df['Character']).most_common(10)[i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WBGYa_x2vgd",
        "colab_type": "code",
        "outputId": "131d132f-081b-4fd9-e1b0-f4505311718e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Посмотрим на состав главных персонажей\n",
        "main_characters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cartman',\n",
              " 'Stan',\n",
              " 'Kyle',\n",
              " 'Butters',\n",
              " 'Randy',\n",
              " 'Mr. Garrison',\n",
              " 'Chef',\n",
              " 'Kenny',\n",
              " 'Sharon',\n",
              " 'Mr. Mackey']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sPsoq_ynUN2",
        "colab_type": "code",
        "outputId": "82928855-6985-4b6e-8b52-ab9adecf13cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Сделаем датасет только с главными героями\n",
        "dfmc = df[df['Character'].isin(main_characters)]\n",
        "len(dfmc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD7cc1Ac43PG",
        "colab_type": "text"
      },
      "source": [
        "Теперь поставлю себе задачи.<br/>\n",
        "Для начала просто интересно посмотреть на процент оскорбительных фраз.<br/>\n",
        "Задачи: \n",
        "1. Какой процент высказываний оскорбителен?\n",
        "2. У какого персонажа (из главных) этот процент наибольший?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7W2HM-vAxaZ",
        "colab_type": "text"
      },
      "source": [
        "Потом основная задача - написать классификатор, который по фразе<br/> определит героя.\n",
        "<br/>\n",
        "Задачи: \n",
        "3. Обучить модель на тренировочной выборке\n",
        "4. Проверить её с помощью тестовой выборки\n",
        "5. Проверить на известных коронных фразах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJa3mrgdyllC",
        "colab_type": "text"
      },
      "source": [
        "# Оскобительность высказываний"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xsGEcLPeKk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# предсказываем для каждой фразы, оскорбительна она или нет\n",
        "predictions = []\n",
        "for row in df.Line:\n",
        "    predictions.append(int(predict([row])))  # функция из profanity_check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXf9eOY8f7Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Swear'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3QCsCvNgocp",
        "colab_type": "code",
        "outputId": "b04cad34-6984-476e-b0e3-4973354e0a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = len(df[df['Swear'] == 1])\n",
        "b = len(df[df['Swear'] == 0])\n",
        "print(f'{round(a/(a+b), 3)*100}% высказываний оскорбительны')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.1% высказываний оскорбительны\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-NOV_4QBB55",
        "colab_type": "text"
      },
      "source": [
        "Ответ на задачу 1: 7.1% высказываний оскорбительны."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRlbsB2rid-z",
        "colab_type": "code",
        "outputId": "671e41a1-72f9-40ab-e0bd-e3df4ba93037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Теперь посмотрю этот процент по персонажам\n",
        "hero_profanity = {}\n",
        "for hero in main_characters:\n",
        "    a = len(df[df['Swear'] == 1 ][ df['Character'] == hero])  # Оскорбительные\n",
        "    b = len(df[df['Swear'] == 0 ][ df['Character'] == hero])  # Допустимые\n",
        "\n",
        "    print(f'{round(a*100/(a+b), 2)}% высказываний {hero} оскорбительны')\n",
        "\n",
        "    hero_profanity[round(a*100/(a+b), 2)] = hero"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.87% высказываний Cartman оскорбительны\n",
            "6.59% высказываний Stan оскорбительны\n",
            "7.59% высказываний Kyle оскорбительны\n",
            "4.65% высказываний Butters оскорбительны\n",
            "6.0% высказываний Randy оскорбительны\n",
            "9.58% высказываний Mr. Garrison оскорбительны\n",
            "7.2% высказываний Chef оскорбительны\n",
            "13.73% высказываний Kenny оскорбительны\n",
            "3.02% высказываний Sharon оскорбительны\n",
            "5.53% высказываний Mr. Mackey оскорбительны\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPH-rsaBB-VP",
        "colab_type": "code",
        "outputId": "912a000b-9f2f-4f5f-a652-d2575992dc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_profanity = max(hero_profanity.keys())\n",
        "swindler = hero_profanity[max_profanity]\n",
        "print(f\"Главный грубиян = это {swindler}. {max_profanity}% его фраз грубые.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Главный грубиян = это Kenny. 13.73% его фраз грубые.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6pI_nudE8bt",
        "colab_type": "text"
      },
      "source": [
        "Вот и ответ на задачу 2. Достаточно интересный результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PLBwOfty5Fl",
        "colab_type": "text"
      },
      "source": [
        "# Предсказание персонажа"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Y2uPx3HItF",
        "colab_type": "text"
      },
      "source": [
        "Теперь займёмся моделью, которая будет предсказывать персонажа по фразе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7SAmEnEzsu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Список знаков препинания\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Список стоп-слов (то есть слов, которые удалим из данных, они засоряют их)\n",
        "# Эти слова встречаются часто и несут мало информации для классификации\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Загрузим из spaCy модель для предварительного анализа английского языка,\n",
        "# то бишь аннотации \n",
        "parser = English()\n",
        "\n",
        "class predictors(TransformerMixin):\n",
        "    \"\"\"\n",
        "    Хотим сделать красиво, с пайплайном, так что вот класс \"предикторы\",\n",
        "    который будет трансформировать текст (предиктор при обучении), делая все\n",
        "    буквы строчными и убирая пробелы.\n",
        "    \"\"\"\n",
        "\n",
        "    def transform(self, X, **transform_params):\n",
        "        # все буквы строчные, без пробелов\n",
        "        return [text.strip().lower() for text in X]\n",
        "\n",
        "    # то, что ниже, надо для пайплайна\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "    \"\"\"\n",
        "    Функция для токенизирования предложения, т.е. приведения в подходящий вид.\n",
        "    (без пунктуации, без \"стоп-слов\", от слов остаются только их корни)\n",
        "    \"\"\"\n",
        "\n",
        "    # Парсим предложение с помощью spaCy\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Оставляем у слов только корни (это называется лемматизация) \n",
        "    mytokens = [word.lemma_.lower().strip()\n",
        "                if word.lemma_ != \"-PRON-\"  # Так (c -PRON-) рекомендуют делать\n",
        "                else word.lower_ for word in mytokens]\n",
        "\n",
        "    # Убираем засоряющие текст \"стоп-слова\"\n",
        "    mytokens = [word for word in mytokens\n",
        "                if word not in stop_words and word not in punctuations]\n",
        "\n",
        "    return mytokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBN0jR0Az0-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Строку текста - в числа\n",
        "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4P3tho20VIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dfmc.Line\n",
        "y = dfmc.Character\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_fdtLt004BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Интересно использовать несколько моделей\n",
        "LRclassifier = LogisticRegression()  # Логистическая регрессия\n",
        "RFclassifier = RandomForestClassifier()  # Случайный лес\n",
        "SVMclassifier = LinearSVC()  # Вариация метода опорных векторов\n",
        "\n",
        "# Ниже инициализируем пайплайны для каждого из классификаторов\n",
        "LRpipe = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', bow_vector),\n",
        "                 ('classifier', LRclassifier)])\n",
        "\n",
        "RFpipe = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', bow_vector),\n",
        "                 ('classifier', RFclassifier)])\n",
        "\n",
        "SVMpipe = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', bow_vector),\n",
        "                 ('classifier', RFclassifier)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjZvyy6HSLly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LRpipe.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWJr_fjLSW7I",
        "colab_type": "code",
        "outputId": "e60732e9-3c7b-4d01-a7b7-dff174e0c92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "RFpipe.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7f48b58750f0>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 t...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i39PPOqBSbtu",
        "colab_type": "code",
        "outputId": "54b25860-bb4b-4273-e5d6-2908e45d1cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "SVMpipe.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7f48b58750b8>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 t...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw5DGlzK0_xc",
        "colab_type": "code",
        "outputId": "c79a1816-4013-4a7e-cfca-bb309a5a171c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Предсказываем на тестовом датасете\n",
        "LRpredicted = LRpipe.predict(X_test)\n",
        "RFpredicted = RFpipe.predict(X_test)\n",
        "SVMpredicted = SVMpipe.predict(X_test)\n",
        "\n",
        "# Accuracy моделей\n",
        "print(\"Accuracy логистической регресии:\",\n",
        "      metrics.accuracy_score(y_test, LRpredicted))\n",
        "\n",
        "print(\"Accuracy случайного леса:\",\n",
        "      metrics.accuracy_score(y_test, RFpredicted))\n",
        "\n",
        "print(\"Accuracy классификации методом опорных векторов:\",\n",
        "      metrics.accuracy_score(y_test, SVMpredicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy логистической регресии: 0.42845911949685533\n",
            "Accuracy случайного леса: 0.3902319182389937\n",
            "Accuracy классификации методом опорных векторов: 0.3902319182389937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkIjsYEhcQ1w",
        "colab_type": "text"
      },
      "source": [
        "С помошью лучшей модели предскажем коронные фразы некоторых персонажей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElzlUC1l3X_7",
        "colab_type": "code",
        "outputId": "9f907c63-236d-466a-da17-7e10e694dc8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LRpipe.predict([\"Oh my god, they've killed Kenny!\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Stan'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zl7cLQ23YWD",
        "colab_type": "code",
        "outputId": "074775b5-1451-41c1-bff8-b8fcee18dcb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LRpipe.predict([\"You bastards!\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Kyle'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blzGwiiQ2a-7",
        "colab_type": "code",
        "outputId": "cd8bc695-da38-4bbb-8a87-3f8e08694634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LRpipe.predict([\"I'm not fat, I'm big boned!\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Cartman'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MShXNarX3ns2",
        "colab_type": "code",
        "outputId": "5738b20f-6f98-41bd-baff-2f076f055a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LRpipe.predict([\"Hello there, children\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Chef'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG-9jOa94riN",
        "colab_type": "code",
        "outputId": "f1668db7-1731-428b-b09e-af5d8cf9e72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LRpipe.predict([\"Oh, hamburgers!\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Butters'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}